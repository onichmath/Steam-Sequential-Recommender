{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d63a9cc-5c1b-4847-b549-48125c57b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl \n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import nn\n",
    "import implicit # For BPR\n",
    "from scipy.sparse import coo_matrix, csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345054f-2407-469e-8571-34986573e130",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ac105b-4d1f-47cd-8e00-bf7aa2ffde5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 868_798\n",
    "val_len = 113_979\n",
    "test_len = 113_979\n",
    "total_len = train_len + val_len + test_len\n",
    "assert total_len == 1_096_756\n",
    "num_users = 113_979\n",
    "num_items = 8_609\n",
    "k_vals = [3, 5, 10, 25, 50]\n",
    "SEED = 42\n",
    "\n",
    "def build_results_df(model_name, k_vals, hits_at_k, precision_at_k):\n",
    "    \"\"\"\n",
    "    Returns a DataFrame with the results of the model, given lists of k_vals, hits_at_k, and precision_at_k\n",
    "    \"\"\" \n",
    "    return pl.DataFrame(\n",
    "        {\n",
    "            \"model\": [model_name] * len(k_vals),\n",
    "            \"k\": k_vals,\n",
    "            \"hits_at_k\": hits_at_k,\n",
    "            \"precision_at_k\": precision_at_k\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d0e66-85cb-42d8-86d4-4a88e2ddbdbf",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a051eb4c-ec56-4e9e-8838-15dcdf839e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_full_data():\n",
    "    \"\"\"\n",
    "    Returns the full dataset sorted by user_id\n",
    "    \"\"\"\n",
    "    exclude_cols = [\"hours\", \"products\", \"found_funny\", \"hours\", \"text\"]\n",
    "    df = pl.scan_parquet(\"data/reviews.parquet\")\n",
    "    print(df.collect())\n",
    "\n",
    "def load_train_val_test_data(): \n",
    "    \"\"\"\n",
    "    Returns datasets sorted by user_id with idx of their initial position in the dataset\n",
    "    - X_train: All interactions except the last two per user\n",
    "    - y_valid: Second to last interaction per user\n",
    "    - y_test: Last interaction per user\n",
    "    \"\"\"\n",
    "    exclude_cols = [\"hours\", \"products\", \"found_funny\", \"hours\", \"text\"]\n",
    "    full = pl.scan_parquet(\"data/sorted_reviews.parquet\").drop(exclude_cols).with_row_index(\"idx\")\n",
    "    y = full.group_by(\"mapped_user_id\").tail(2)\n",
    "    X_train = full.join(y, on=\"idx\", how=\"anti\") # Up to two interactions from last per user\n",
    "\n",
    "    y_valid = y.group_by(\"mapped_user_id\").head(1) # 1 interaction from last per user\n",
    "    y_test = y.group_by(\"mapped_user_id\").tail(1) # Last interaction per user\n",
    "\n",
    "    assert total_len == len(full.collect())\n",
    "    assert train_len == len(X_train.collect())\n",
    "    assert val_len == len(y_valid.collect())\n",
    "    assert test_len == len(y_test.collect())\n",
    "\n",
    "    return X_train, y_valid, y_test\n",
    "\n",
    "def format_train_eval_data(df, cols_to_keep=[\"idx\", \"user_id\", \"product_id\"]): \n",
    "    \"\"\"\n",
    "    Formats the data to have the columns: idx, user_id, product_id\n",
    "    \"\"\"\n",
    "    exclude_cols = [\"review_date\", \"mapped_user_id\", \"mapped_product_id\"]\n",
    "    return (\n",
    "        df\n",
    "        .with_columns(\n",
    "            pl.col(\"mapped_user_id\").alias(\"user_id\"),\n",
    "            pl.col(\"mapped_product_id\").alias(\"product_id\"),\n",
    "        )\n",
    "        .drop(exclude_cols)\n",
    "        .select(cols_to_keep)\n",
    "    )\n",
    "\n",
    "def get_clean_train_valid_eval(): \n",
    "    \"\"\" \n",
    "    Returns the datasets formatted for training and evaluation\n",
    "    - X_train: All interactions except the last two per user\n",
    "    - y_valid: Second to last interaction per user\n",
    "    - y_test: Last interaction per user\n",
    "    \"\"\"\n",
    "    X_train, y_valid, y_test = load_train_val_test_data()\n",
    "    X_train = format_train_eval_data(X_train)\n",
    "    y_valid = format_train_eval_data(y_valid)\n",
    "    y_test = format_train_eval_data(y_test)\n",
    "    assert total_len == len(X_train.collect()) + len(y_valid.collect()) + len(y_test.collect())\n",
    "    return X_train, y_valid, y_test\n",
    "\n",
    "def join_train_valid(X_train, y_valid):\n",
    "    \"\"\"\n",
    "    Joins the training and validation datasets on each user \n",
    "    - X_test: All interactions except the last one per user\n",
    "    \"\"\"\n",
    "    X_test = pl.concat([X_train, y_valid], how=\"vertical\").sort(\"idx\")\n",
    "    assert train_len + val_len == len(X_test.collect())\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02f92d4-43ae-4127-a268-5775802331a7",
   "metadata": {},
   "source": [
    "## Baseline Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9503f8fe-fe31-4933-ab44-9c87352e92cd",
   "metadata": {},
   "source": [
    "### Experiment 1: Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d57e3a6-a358-403a-851d-9072b421e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_popular_items(X, k=50): \n",
    "    \"\"\"\n",
    "    Returns the k most popular items in X\n",
    "    \"\"\"\n",
    "    popular_items = (\n",
    "        X\n",
    "        .group_by(\"product_id\")\n",
    "        .agg(pl.count(\"product_id\").alias(\"count\"))\n",
    "        .sort(\"count\", descending=True)\n",
    "        .head(k)\n",
    "    )\n",
    "    return popular_items\n",
    "    \n",
    "def predict_based_on_item_popularity(X_train, y_valid, y_test, k=50): \n",
    "    \"\"\"\n",
    "    Predicts the most popular items for each user\n",
    "    \"\"\"\n",
    "    top_k_items = get_k_most_popular_items(\n",
    "        join_train_valid(X_train, y_valid),\n",
    "        k)\n",
    "    return y_test.join(top_k_items, on=\"product_id\")\n",
    "\n",
    "def popularity_baseline(k_vals = k_vals):\n",
    "    X_train, y_valid, y_test = get_clean_train_valid_eval()\n",
    "    \n",
    "    hits_at_k = []\n",
    "    precision_at_k = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        y_pred = predict_based_on_item_popularity(X_train, y_valid, y_test, k = k)\n",
    "        hits = len(y_pred.join(y_test, on=[\"user_id\", \"product_id\"]).collect())\n",
    "\n",
    "        num_predictions = len(y_pred.collect())\n",
    "        number_of_users = len(y_test.collect()) \n",
    "\n",
    "        hits_at_k.append(hits / number_of_users)\n",
    "\n",
    "        # Number of hits divided by number of predictions\n",
    "        precision_at_k.append(hits / k / number_of_users)\n",
    "\n",
    "    results = build_results_df(\"popularity\", k_vals, hits_at_k, precision_at_k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c73ed84b-5a1b-4551-961c-254725879390",
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_baseline().write_csv(\"results/popularity_baseline.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89146ddb-b548-4ea1-90b5-2b2f12800ae2",
   "metadata": {},
   "source": [
    "### Experiment 2: Markov Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8bb0b90-03f9-4b26-afad-508226af3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix_from_markov_chain(X):\n",
    "    \"\"\"\n",
    "    Builds a transition matrix from transition counts\n",
    "    OLD Method, stopped using it since it cannot be Lazy\n",
    "    \"\"\"\n",
    "    return (\n",
    "            X.collect()\n",
    "            .pivot(\n",
    "                on=\"prev_product_id\",\n",
    "                index=\"product_id\",\n",
    "                values=\"transitions\",\n",
    "                aggregate_function=\"sum\"\n",
    "            )\n",
    "            .fill_null(0)\n",
    "            .rename({\"product_id\": \"next_product_id\"})\n",
    "            .with_columns(pl.all().exclude(\"next_product_id\") / pl.all().sum())\n",
    "            .lazy()\n",
    "        )\n",
    "\n",
    "def get_matrix_shifted_by_3(X):\n",
    "    \"\"\"\n",
    "    Returns matrix shifted by 3\n",
    "    \"\"\"\n",
    "    return (\n",
    "        X.with_columns([\n",
    "            pl.col(\"product_id\").shift(1).alias(\"prev_1_product_id\"),\n",
    "            pl.col(\"user_id\").shift(1).alias(\"prev_1_user_id\"),\n",
    "            pl.col(\"product_id\").shift(2).alias(\"prev_2_product_id\"),\n",
    "            pl.col(\"user_id\").shift(2).alias(\"prev_2_user_id\"),\n",
    "            pl.col(\"product_id\").shift(3).alias(\"prev_3_product_id\"),\n",
    "            pl.col(\"user_id\").shift(3).alias(\"prev_3_user_id\"),\n",
    "        ])\n",
    "        .filter(pl.col(\"prev_3_product_id\").is_not_null())\n",
    "        .filter(pl.col(\"user_id\") == pl.col(\"prev_3_user_id\"))\n",
    "    )\n",
    "\n",
    "def get_previous_n_transitions(X, n=1):\n",
    "    \"\"\"\n",
    "    Returns the previous n transitions for each user weighted by how far back they are\n",
    "    \"\"\"\n",
    "    prev_column = f\"prev_{n}_product_id\"\n",
    "    return (\n",
    "        X\n",
    "        .group_by([prev_column, \"product_id\"])\n",
    "        .len().rename({\"len\": \"transitions\"})\n",
    "        .with_columns([pl.col(\"transitions\") / n])\n",
    "        .rename({prev_column: \"prev_product_id\"})\n",
    "    )\n",
    "\n",
    "def get_3rd_order_markov_chain(X):\n",
    "    \"\"\"\n",
    "    Returns the transition probabilities for a 3rd order Markov chain\n",
    "    \"\"\"\n",
    "    X_shifted = get_matrix_shifted_by_3(X)\n",
    "    \n",
    "    n_1_transition_counts = get_previous_n_transitions(X_shifted, n=1)\n",
    "    n_2_transition_counts = get_previous_n_transitions(X_shifted, n=2)\n",
    "    n_3_transition_counts = get_previous_n_transitions(X_shifted, n=3)\n",
    "\n",
    "    transition_counts = pl.concat([n_1_transition_counts, n_2_transition_counts, n_3_transition_counts])\n",
    "    \n",
    "    transition_probs = (\n",
    "        transition_counts\n",
    "        .with_columns(pl.col(\"transitions\") / pl.col(\"transitions\").sum().over(\"prev_product_id\"))\n",
    "        .rename({\n",
    "            \"transitions\": \"probability\",\n",
    "            \"product_id\": \"next_product_id\",\n",
    "            \"prev_product_id\": \"product_id\",\n",
    "            })\n",
    "    )\n",
    "    \n",
    "    return transition_probs\n",
    "\n",
    "def predict_based_on_markov_chain(y, transition_matrix, k=50):\n",
    "    \"\"\"\n",
    "    Predicts the next k items based on the transition matrix\n",
    "    \"\"\"\n",
    "    y_pred =  (\n",
    "        y\n",
    "        .drop(\"idx\")\n",
    "        .join(transition_matrix, on=\"product_id\", how=\"left\")\n",
    "        .group_by(\"user_id\")\n",
    "        .agg(\n",
    "            [\n",
    "                pl.struct([\"next_product_id\", \"probability\"])\n",
    "                .sort_by(\"probability\", descending=True)\n",
    "                .slice(0, k)\n",
    "                .alias(\"top_predictions\")\n",
    "            ]\n",
    "        )\n",
    "        .explode(\"top_predictions\")\n",
    "        .select(\n",
    "            \"user_id\",\n",
    "            pl.col(\"top_predictions\").struct.field(\"next_product_id\").alias(\"product_id\"),\n",
    "            pl.col(\"top_predictions\").struct.field(\"probability\").alias(\"probability\"),\n",
    "        )\n",
    "    )\n",
    "    return y_pred\n",
    "\n",
    "def markov_chain_experiment(k_vals = k_vals):\n",
    "    X_train, y_valid, y_test = get_clean_train_valid_eval()\n",
    "    X_test = join_train_valid(X_train, y_valid)\n",
    "\n",
    "    transition_matrix = get_3rd_order_markov_chain(X_test)\n",
    "    hits_at_k = []\n",
    "    precision_at_k = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        y_pred = predict_based_on_markov_chain(y_valid, transition_matrix, k = k)\n",
    "        hits = len(y_pred.join(y_test, on=[\"user_id\", \"product_id\"]).collect())\n",
    "\n",
    "        num_predictions = len(y_pred.collect())\n",
    "        number_of_users = len(y_test.collect()) \n",
    "\n",
    "        hits_at_k.append(hits / number_of_users)\n",
    "        precision_at_k.append(hits / k / number_of_users)\n",
    "\n",
    "    results = build_results_df(\"Markov Chain\", k_vals=k_vals, hits_at_k=hits_at_k, precision_at_k=precision_at_k)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c37488d-0f2a-40ca-8cff-8550e1f0c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_chain_experiment().write_csv(\"results/markov_chain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d391e614-4aba-4685-99ac-7100294fb221",
   "metadata": {},
   "source": [
    "## Transformer Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffb0967c-3f1f-487c-b2f2-e621025d9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1_096_756, 7)\n",
      "┌────────┬──────────┬────────────┬──────────────────┬─────────────┬──────────────────┬─────────────┐\n",
      "│ hours  ┆ products ┆ product_id ┆ text             ┆ found_funny ┆ user_id          ┆ review_date │\n",
      "│ ---    ┆ ---      ┆ ---        ┆ ---              ┆ ---         ┆ ---              ┆ ---         │\n",
      "│ f64    ┆ i64      ┆ i32        ┆ str              ┆ i64         ┆ i64              ┆ date        │\n",
      "╞════════╪══════════╪════════════╪══════════════════╪═════════════╪══════════════════╪═════════════╡\n",
      "│ 16.6   ┆ 577      ┆ 35140      ┆ Still worth      ┆ null        ┆ 7656119800748307 ┆ 2018-01-04  │\n",
      "│        ┆          ┆            ┆ playing in 2018. ┆             ┆ 5                ┆             │\n",
      "│        ┆          ┆            ┆ P…               ┆             ┆                  ┆             │\n",
      "│ 3.8    ┆ 431      ┆ 328100     ┆ A nice game, but ┆ 2           ┆ 7656119806068674 ┆ 2017-06-23  │\n",
      "│        ┆          ┆            ┆ better not to…   ┆             ┆ 9                ┆             │\n",
      "│ 14.8   ┆ 147      ┆ 35140      ┆ aweosme game     ┆ null        ┆ 7656119802349140 ┆ 2018-01-03  │\n",
      "│        ┆          ┆            ┆ great story and  ┆             ┆ 1                ┆             │\n",
      "│        ┆          ┆            ┆ s…               ┆             ┆                  ┆             │\n",
      "│ 1.3    ┆ 1689     ┆ 328100     ┆ They do a        ┆ null        ┆ 7656119801196536 ┆ 2017-03-31  │\n",
      "│        ┆          ┆            ┆ fantastic job of ┆             ┆ 5                ┆             │\n",
      "│        ┆          ┆            ┆ mat…             ┆             ┆                  ┆             │\n",
      "│ 9.5    ┆ 418      ┆ 506510     ┆ Overall I find   ┆ null        ┆ 7656119799929496 ┆ 2017-12-28  │\n",
      "│        ┆          ┆            ┆ Shadows of Adam… ┆             ┆ 4                ┆             │\n",
      "│ …      ┆ …        ┆ …          ┆ …                ┆ …           ┆ …                ┆ …           │\n",
      "│ 1460.4 ┆ 195      ┆ 252490     ┆ Great game!      ┆ null        ┆ 7656119798106810 ┆ 2013-12-11  │\n",
      "│        ┆          ┆            ┆                  ┆             ┆ 9                ┆             │\n",
      "│ 721.1  ┆ 45       ┆ 252490     ┆ 10/10 Garry      ┆ null        ┆ 7656119803907376 ┆ 2013-12-11  │\n",
      "│        ┆          ┆            ┆ newman makes the ┆             ┆ 8                ┆             │\n",
      "│        ┆          ┆            ┆ b…               ┆             ┆                  ┆             │\n",
      "│ 1460.4 ┆ 195      ┆ 252490     ┆ Great game!      ┆ null        ┆ 7656119798106810 ┆ 2013-12-11  │\n",
      "│        ┆          ┆            ┆                  ┆             ┆ 9                ┆             │\n",
      "│ 239.9  ┆ 749      ┆ 252490     ┆ good game        ┆ null        ┆ 7656119797062224 ┆ 2013-12-11  │\n",
      "│        ┆          ┆            ┆ everybody buy    ┆             ┆ 2                ┆             │\n",
      "│        ┆          ┆            ┆ now!             ┆             ┆                  ┆             │\n",
      "│ 348.7  ┆ 166      ┆ 252490     ┆ This game is     ┆ null        ┆ 7656119799087860 ┆ 2013-12-11  │\n",
      "│        ┆          ┆            ┆ actually very    ┆             ┆ 8                ┆             │\n",
      "│        ┆          ┆            ┆ fun…             ┆             ┆                  ┆             │\n",
      "└────────┴──────────┴────────────┴──────────────────┴─────────────┴──────────────────┴─────────────┘\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'collect'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(full\u001b[38;5;241m.\u001b[39mcollect())\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mexamine_data_for_transformers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mexamine_data_for_transformers\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexamine_data_for_transformers\u001b[39m():\n\u001b[1;32m      2\u001b[0m     full \u001b[38;5;241m=\u001b[39m load_full_data()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mfull\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m())\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'collect'"
     ]
    }
   ],
   "source": [
    "def examine_data_for_transformers():\n",
    "    full = load_full_data()\n",
    "    print(full.collect())\n",
    "    users = full.group_by(\"user_id\").agg(pl.count(\"product_id\").alias(\"count\")).filter(pl.col(\"count\") < 5).select(\"user_id\").collect()\n",
    "    items = full.group_by(\"product_id\").agg(pl.count(\"user_id\").alias(\"count\")).filter(pl.col(\"count\") < 5).select(\"product_id\").collect()\n",
    "    # drop rows with users less than 5\n",
    "    full = full.filter(~pl.col(\"user_id\").is_in(users)).collect()\n",
    "    print(full)\n",
    "    pass\n",
    "examine_data_for_transformers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b339e69-fb8e-4776-9889-c5043736c7c9",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a4f3bd-f2ca-48bc-9ddd-098032d9981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialRecommenderDataset(Dataset):\n",
    "    def __init__(self, X, y, context_len):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c0e2a-45fc-4ac6-962e-7da7625f14d8",
   "metadata": {},
   "source": [
    "### Experiment 3: Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f95e66-9ec6-4015-870a-fc41346a662e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
